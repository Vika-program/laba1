# Лаба 1: Калькулятор (сложность M2)

## Запуск программы
python -m src.main

## Запуск тестов
uv run python -m pytest

## Формат ввода
* Выражение вводится в обычной записи
* Доступны операторы +, -, *, /, //, **, %
* На ноль делить нельзя
* Операторы %, // только для целых чисел
* Поддерживаются унарные операторы, но они обязательно должны быть записаны в отдельных скобках
* Дробные числа записываются через точку, без пробела
* Все открытые скобки долны быть закрыты
* В скобках может быть одно число, но не может быть оператор или оператор + число
* Строка дожна представлять собой корректное математическое выражение, не допустимы такие записи: "1 1 + ", "1 +" и т. д.
* При неправильном вводе выдаются сообщения об ошибке
* Чтобы завершить программу, нужно нажать enter

## Принятые решения
1. Поскольку я не знаю, какой алгоритм лучше работает, хочу привести две версии токенизации: в одной больше регулярных выражений(1), а в другой - условий(2).
Чтобы переключиться между ними нужно поменять название функции tokenize на tokenize_2 и наоборот, и несколько строчек кода в файле trans:

    `#if not is_correct(expr):
        #raise CalcError('Выражение некорректно') #раскомментировать стороку, если используете tokenize
    expr = tokenize(expr) # можно поменять на tokenize`
2. #### Теперь опишу структуру кода: 
* В файле **_other_** хранятся вспомогательные функции is_op, is_num и класс ошибок CalcError
* В файле **_tokenize_2_** хранится функция tokenize_2 (2 вариант токенизации)
* В файле **_is_correct_** хранится функция is_correct (используется для 1 варианта токенизации)
* В файле **_tokenize_** хранится функция tokenize (используется для 1 варианта токенизации)
* В файле **_trans_** хранится функция trans_to_rpn
* В файле **_calc_** хранится функция calc
* В файле **_main_** выполняется сама программа

_Примечание:_ в моем коде функции вложены друг в друга

3. Пользователь может вводить выражение как с пробелами, так и без них, поэтому при токенизации я сама добавляю пробелы, 
где нужно, чтобы потом по ним разделить строку.


## Алгоритм

### Токенизация

* #### 1 вариант
Сначала проверяем выражение на корректность, 
используя регулярные выражения и счётчик скобок (функция is_correct), 
потом добавляем пробелы, и по ним разбиваем строку на токены (функция tokenize) 
(унарный знак и число находятся в одном токене)
* #### 2 вариант
В одной функции (tokenize_2) сразу обрабатываем 
исключения и разбиваем строку на токены
(используем больше условий, чтобы учесть все случаи, больше видов 
сообщений об ошибках, чем в 1 варианте)

### Перевод выражения в польскую запись
Проходимся по токенам, если видим **число** - добавляем в список res,
если **операцию**, то добавляем её в список res, удаляя из op_trans,
пока op_trans не пустой список, последний символ является операцией 
и выше или равен по приоритету последнему в op_trans, 
затем добавляем в список op_trans токен.
Если видим **открывающую скобку** - добавляем в op_trans, 
если **закрывающую**, то, пока не увидим открывающую скобку, 
добавляем всё в res, удаляя из op_trans, потом удаляем открывающую скобку.
В конце добавляем оставшиеся операции и возвращаем список res

### Вычисление
Проходимся по токенам в польской записи, если видим число 
добавляем в stack, если операцию - вычисляем значение 
и добавляем его в stack. В функции обрабатываем 
исключений и выводим ответ.

## Допущения
* Унарные операторы должны быть в отдельных скобках всегда
* Допустимы лишние скобки, если они все парные и не противоречат правилам
* Допустимо ввести одно число, тогда программа его и вернёт

